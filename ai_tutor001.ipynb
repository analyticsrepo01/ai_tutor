{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ea56e7-361c-4fab-a20b-975a11df3eaf",
   "metadata": {},
   "source": [
    "### Tutor to generate question from a given book's section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fed9dcbd-bd5f-40ae-9585-96ea538d9ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "SVC_ACC = !(gcloud config get-value core/account)\n",
    "SVC_ACC = SVC_ACC[0]\n",
    "\n",
    "PROJECT_NUMBER=str(re.search(r'\\d+', SVC_ACC).group())\n",
    "\n",
    "LOCATION=\"asia-southeast1\"\n",
    "\n",
    "FOLDER_NAME=\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d0ab9c-3780-4db2-b8e3-ee2ba901e6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aifs\n",
      "  Using cached aifs-0.0.16-py3-none-any.whl.metadata (3.1 kB)\n",
      "Using cached aifs-0.0.16-py3-none-any.whl (54 kB)\n",
      "Installing collected packages: aifs\n",
      "Successfully installed aifs-0.0.16\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install aifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c86fcbd7-8691-491b-ac69-b429af02a4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aifs import search\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb754687-3488-4f39-9a16-5e493540fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def File_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches document folder for relevant document excerpts.\n",
    "    \n",
    "    Args:\n",
    "        query for docs folder.\n",
    "    \n",
    "    Returns:\n",
    "        str: Document execerpts.\n",
    "    \"\"\"\n",
    "    name: str = \"story_file_search\"\n",
    "    description: str = (\n",
    "        \"A tool to search for ACME information\"\n",
    "        \"Useful for when you need to answer questions about ACME programs. \"\n",
    "        \"Input should be a search query.\"\n",
    "    )\n",
    "    result = search(\n",
    "        query=query,\n",
    "        #replace path to your file below with your file path\n",
    "        path=\"./chapter1.pdf\",\n",
    "        max_results=5\n",
    "    )\n",
    "    print(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54b2cc1e-72a1-4c0c-91ab-944e68fa38f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import tool\n",
    "# from langchain_vertexai import ChatGemini\n",
    "from crewai_tools.tools import FileReadTool\n",
    "import os, requests, re, mdpdf, subprocess\n",
    "from vertexai.preview.vision_models import ImageGenerationModel\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "import uuid, os\n",
    "\n",
    "# Initialize Gemini LLM\n",
    "llm = ChatVertexAI(\n",
    "    model_name=\"gemini-pro-1.5\", # Replace with your desired Gemini model\n",
    "    project_id=os.getenv(PROJECT_ID), # Your Vertex AI project ID\n",
    "    location=\"us-central1\", # Your Vertex AI location\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "976ab33c-3211-41cc-b906-7ba63f9f8e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "\n",
    "#You can choose to use a local model through Ollama for example.\n",
    "#\n",
    "# from langchain_community.llms import Ollama\n",
    "# ollama_llm = Ollama(model=\"openhermes\")\n",
    "\n",
    "#Install duckduckgo-search for this example:\n",
    "#!pip install -U duckduckgo-search\n",
    "\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "search_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a5958f6-8bb4-4fe2-bc9a-06d80141221c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Task\nexpected_output\n  Field required [type=missing, input_value={'description': 'Use the ...ch at 0x7fa5b3d6cae0>)]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m\n\u001b[1;32m      2\u001b[0m researcher \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m      3\u001b[0m   role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresearcher\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m   goal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummarize info from file_search\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m writer \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m     20\u001b[0m   role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACME Programs Background Info Writer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m   goal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCraft reports with information about ACME programs\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m   max_rpm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m task1 \u001b[38;5;241m=\u001b[39m \u001b[43mTask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mUse the document search tool to Conduct a comprehensive analysis of the ACME information in the document library. You must use the search tool provided, information should be from documents searched with that tool.\u001b[39;49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;43m  Your final answer MUST be a full list of information related to ACME, the organizations associated, and the schedules associated. Include some verbatim excerpts from any document searches. Use the File_search tool.\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m  \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresearcher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mFile_search\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m task2 \u001b[38;5;241m=\u001b[39m Task(\n\u001b[1;32m     41\u001b[0m   description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mUsing the insights provided, develop an engaging report that explains information related to ACME.\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124m  Your post should be informative yet accessible, catering to the audience.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Instantiate your crew with a sequential process\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/crewai/task.py:100\u001b[0m, in \u001b[0;36mTask.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(__pydantic_self__, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata):\n\u001b[1;32m     99\u001b[0m     config \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/r/lib/python3.12/site-packages/pydantic/main.py:176\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    175\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Task\nexpected_output\n  Field required [type=missing, input_value={'description': 'Use the ...ch at 0x7fa5b3d6cae0>)]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define your agents with roles and goals\n",
    "researcher = Agent(\n",
    "  role='researcher',\n",
    "  goal='Summarize info from file_search',\n",
    "  backstory=\"\"\"You are good at using file_search to search docs and summarize info.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=True,\n",
    "  tools=[File_search],\n",
    "  llm=llm\n",
    "  \n",
    "  \n",
    "  # You can pass an optional llm attribute specifying what mode you wanna use.\n",
    "  # It can be a local model through Ollama / LM Studio or a remote\n",
    "  # model like vertexai, Mistral, Antrophic of others (https://python.langchain.com/docs/integrations/llms/)\n",
    "  #  # Examples:xx\n",
    "  \n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "  role='ACME Programs Background Info Writer',\n",
    "  goal='Craft reports with information about ACME programs',\n",
    "  backstory=\"\"\"You are a renowned wrier with years experience, known for\n",
    "  your insightful skills and extensive experience working in the domain.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=True,\n",
    "  llm=llm,\n",
    "  max_iter=200,\n",
    "  max_rpm=20\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "task1 = Task(\n",
    "  description=\"\"\"Use the document search tool to Conduct a comprehensive analysis of the ACME information in the document library. You must use the search tool provided, information should be from documents searched with that tool.\n",
    "  Your final answer MUST be a full list of information related to ACME, the organizations associated, and the schedules associated. Include some verbatim excerpts from any document searches. Use the File_search tool.\"\"\",\n",
    "  agent=researcher,\n",
    "  tools=[File_search]\n",
    ")\n",
    "\n",
    "task2 = Task(\n",
    "  description=\"\"\"Using the insights provided, develop an engaging report that explains information related to ACME.\n",
    "  Your post should be informative yet accessible, catering to the audience.\n",
    "  Make it sound professional.\n",
    "  Your final answer MUST be a complete reporting of the information with at least 4 paragraphs.\"\"\",\n",
    "  agent=writer\n",
    "  \n",
    "\n",
    ")\n",
    "\n",
    "# Instantiate your crew with a sequential process\n",
    "crew = Crew(\n",
    "  agents=[researcher, writer],\n",
    "  #agents=[researcher1],\n",
    "  tasks=[task1, task2],\n",
    "  #tasks=[task0],\n",
    "  verbose=2, # You can set it to 1 or 2 to different logging levels\n",
    ")\n",
    "\n",
    "# Get your crew to work!\n",
    "result = crew.kickoff()\n",
    "\n",
    "print(\"######################\")\n",
    "print(result)\n",
    "# @analyticsrepo01\n",
    "# Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11352cf7-f8f9-46b5-8aee-1a35e98b8ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py312",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "py312 (Local)",
   "language": "python",
   "name": "conda-root-py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
